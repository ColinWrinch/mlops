{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Week-13 MLS: Finsights Grey - RAG for Effective Information Retrieval**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Business Use Case**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem Statement:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finsights Grey Inc. is an innovative financial technology firm that specializes in providing advanced analytics and insights for investment management and financial planning. The company handles an extensive collection of 10-K reports from various industry players, which contain detailed information about financial performance, risk factors, market trends, and strategic initiatives. Despite the richness of these documents, Finsights Grey's financial analysts struggle with extracting actionable insights efficiently in a short span due to the manual and labor-intensive nature of the analysis. Going through the document to find the exact information needed at the moment takes too long. This bottleneck hampers the company's ability to deliver timely and accurate recommendations to its clients. To overcome these challenges, Finsights Grey Inc. aims to implement a Retrieval-Augmented Generation (RAG) model to automate the extraction, summarization, and analysis of information from the 10-K reports, thereby enhancing the accuracy and speed of their investment insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objective:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a Gen AI Data Scientist hired by Finsights Grey Inc., the objective is to develop an advanced RAG-based system to streamline the extraction and analysis of key information from 10-K reports.\n",
    "\n",
    "The project will involve testing the RAG system on a current business problem. The Financial analysts are asked to research major cloud and AI platforms such as Amazon AWS, Google Cloud, Microsoft Azure, Meta AI, and IBM Watson to determine the most effective platform for this application. The primary goals include improving the efficiency of data extraction. Once the project is deployed, the system will be tested by a financial analyst with the following questions. Accurate text retrieval for these questions will imply the project's success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Questions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Has the company made any significant acquisitions in the AI space, and how are these acquisitions being integrated into the company's strategy?\n",
    "\n",
    "2. How much capital has been allocated towards AI research and development?\n",
    "\n",
    "3. What initiatives has the company implemented to address ethical concerns surrounding AI, such as fairness, accountability, and privacy?\n",
    "\n",
    "4. How does the company plan to differentiate itself in the AI space relative to competitors?\n",
    "\n",
    "Each Question must be asked for each of the five companies.\n",
    "\n",
    "By successfully developing this project, we aim to:\n",
    "\n",
    "Improve the productivity of financial analysts by providing a competent tool.\n",
    "\n",
    "Provide timely insights to improve client recommendations.\n",
    "\n",
    "Strengthen FinTech Insights Inc.’s competitive edge by delivering more reliable and faster insights to clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a FAISS-Based Vector Index for Document Retrieval with Azure Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **In this guide, we'll set up an Azure Machine Learning (AzureML) pipeline to process Tesla's annual reports, generate embeddings, and create a FAISS-based vector index for efficient document retrieval.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Install and Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1732683109828
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-ml in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (6.0.2)\n",
      "Requirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\n",
      "Requirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.31.0)\n",
      "Requirement already satisfied: azure-mgmt-core>=1.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.4.0)\n",
      "Requirement already satisfied: marshmallow>=3.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (3.22.0)\n",
      "Requirement already satisfied: jsonschema>=4.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (4.23.0)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (4.66.5)\n",
      "Requirement already satisfied: strictyaml in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.7.3)\n",
      "Requirement already satisfied: colorama in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\n",
      "Requirement already satisfied: pyjwt in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (2.9.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (12.23.0)\n",
      "Requirement already satisfied: azure-storage-file-share in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (12.18.0)\n",
      "Requirement already satisfied: azure-storage-file-datalake>=12.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (12.17.0)\n",
      "Requirement already satisfied: pydash>=6.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (8.0.3)\n",
      "Requirement already satisfied: isodate in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.6.1)\n",
      "Requirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (4.12.2)\n",
      "Requirement already satisfied: opencensus-ext-azure in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.1.13)\n",
      "Requirement already satisfied: opencensus-ext-logging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.1.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (43.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.20.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from marshmallow>=3.5->azure-ai-ml) (24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.8.30)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2.0.0)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus-ext-azure->azure-ai-ml) (1.18.0)\n",
      "Requirement already satisfied: opencensus<1.0.0,>=0.11.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus-ext-azure->azure-ai-ml) (0.11.4)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus-ext-azure->azure-ai-ml) (6.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from strictyaml->azure-ai-ml) (2.9.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.31.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.17.1)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2.2.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
      "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (5.28.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.24.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.35.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (2.10.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: azureml-rag>=0.2.36 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (0.2.36)\n",
      "Requirement already satisfied: azureml-dataprep>4.11 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (5.1.6)\n",
      "Requirement already satisfied: azureml-fsspec in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.3.1)\n",
      "Requirement already satisfied: fsspec~=2023.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2023.10.0)\n",
      "Requirement already satisfied: openai>=0.27.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.0)\n",
      "Collecting tiktoken<0.6 (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36)\n",
      "  Using cached tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: cloudpickle in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.2.1)\n",
      "Requirement already satisfied: mmh3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (5.0.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (6.0.2)\n",
      "Requirement already satisfied: requests in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.32.3)\n",
      "Requirement already satisfied: azureml-core in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.57.0.post1)\n",
      "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (1.5.2)\n",
      "Requirement already satisfied: sentence-transformers in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (0.26.2)\n",
      "Requirement already satisfied: faiss-cpu~=1.7.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-rag[faiss,hugging_face]>=0.2.36) (1.7.4)\n",
      "Requirement already satisfied: azureml-dataprep-native<42.0.0,>=41.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (41.0.0)\n",
      "Requirement already satisfied: azureml-dataprep-rslex~=2.22.2dev0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.22.4)\n",
      "Requirement already satisfied: azure-identity>=1.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.18.0)\n",
      "Requirement already satisfied: jsonschema in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (4.23.0)\n",
      "Requirement already satisfied: pyarrow>=0.17.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (17.0.0)\n",
      "Requirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->azureml-rag[faiss,hugging_face]>=0.2.36) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->azureml-rag[faiss,hugging_face]>=0.2.36) (24.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->azureml-rag[faiss,hugging_face]>=0.2.36) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->azureml-rag[faiss,hugging_face]>=0.2.36) (4.12.2)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.10.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tiktoken<0.6->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2024.8.30)\n",
      "Requirement already satisfied: pytz in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2024.2)\n",
      "Requirement already satisfied: backports.tempfile in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0)\n",
      "Requirement already satisfied: pathspec<1.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.12.1)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.15.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.31.0)\n",
      "Requirement already satisfied: msal-extensions<=2.0.0,>=0.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.0)\n",
      "Requirement already satisfied: knack<0.12.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.11.0)\n",
      "Requirement already satisfied: azure-core<2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.31.0)\n",
      "Requirement already satisfied: pkginfo in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.11.1)\n",
      "Requirement already satisfied: argcomplete<4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.5.0)\n",
      "Requirement already satisfied: humanfriendly<11.0,>=4.7 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (10.0)\n",
      "Requirement already satisfied: paramiko<4.0.0,>=2.0.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.5.0)\n",
      "Requirement already satisfied: azure-mgmt-resource<=24.0.0,>=15.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (23.1.1)\n",
      "Requirement already satisfied: azure-mgmt-containerregistry<11,>=8.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (10.3.0)\n",
      "Requirement already satisfied: azure-mgmt-storage<=22.0.0,>=16.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (21.2.1)\n",
      "Requirement already satisfied: azure-mgmt-keyvault<11.0.0,>=0.40.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (10.3.1)\n",
      "Requirement already satisfied: azure-mgmt-authorization<5,>=0.40.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (4.0.0)\n",
      "Requirement already satisfied: azure-mgmt-network<=26.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (26.0.0)\n",
      "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.61.1)\n",
      "Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.1.28)\n",
      "Requirement already satisfied: msrest<=0.7.1,>=0.5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.7.1)\n",
      "Requirement already satisfied: msrestazure<=0.7,>=0.4.33 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.6.4.post1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.9.0)\n",
      "Requirement already satisfied: ndg-httpsclient<=0.5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.5.1)\n",
      "Requirement already satisfied: SecretStorage<4.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.3)\n",
      "Requirement already satisfied: jsonpickle<4.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3.0)\n",
      "Requirement already satisfied: contextlib2<22.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (21.6.0)\n",
      "Requirement already satisfied: docker<8.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (7.1.0)\n",
      "Requirement already satisfied: PyJWT<3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.9.0)\n",
      "Requirement already satisfied: adal<=1.2.7,>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.7)\n",
      "Requirement already satisfied: pyopenssl<25.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (24.2.1)\n",
      "Requirement already satisfied: jmespath<2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->azureml-rag[faiss,hugging_face]>=0.2.36) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->azureml-rag[faiss,hugging_face]>=0.2.36) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->azureml-rag[faiss,hugging_face]>=0.2.36) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->azureml-rag[faiss,hugging_face]>=0.2.36) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (4.46.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (2.5.1)\n",
      "Requirement already satisfied: Pillow in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (10.4.0)\n",
      "Requirement already satisfied: cryptography>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from adal<=1.2.7,>=1.2.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (43.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.2.2)\n",
      "Requirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.16.0)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.6.1)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-mgmt-authorization<5,>=0.40.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.14.0)\n",
      "Requirement already satisfied: pygments in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from knack<0.12.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.18.0)\n",
      "Requirement already satisfied: tabulate in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from knack<0.12.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.9.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msal-extensions<=2.0.0,>=0.3.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.10.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.0.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ndg-httpsclient<=0.5.1->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.6.1)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (4.2.0)\n",
      "Requirement already satisfied: pynacl>=1.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.27.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.7.1)\n",
      "Requirement already satisfied: jeepney>=0.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from SecretStorage<4.0.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.8.0)\n",
      "Requirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (3.3)\n",
      "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (0.20.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (0.4.5)\n",
      "Requirement already satisfied: backports.weakref in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from backports.tempfile->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.0.post1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (0.20.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (1.17.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers->azureml-rag[faiss,hugging_face]>=0.2.36) (2.1.5)\n",
      "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core->azureml-rag>=0.2.36->azureml-rag[faiss,hugging_face]>=0.2.36) (2.22)\n",
      "Using cached tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Installing collected packages: tiktoken\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.6.0\n",
      "    Uninstalling tiktoken-0.6.0:\n",
      "      Successfully uninstalled tiktoken-0.6.0\n",
      "Successfully installed tiktoken-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the Azure Machine Learning SDK and FAISS-related utilities\n",
    "%pip install azure-ai-ml\n",
    "%pip install -U 'azureml-rag[faiss,hugging_face]>=0.2.36'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Configure Azure Machine Learning Workspace**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get client for AzureML Workspace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "Enter your Workspace details below, running this still will write a `workspace.json` file to the current folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1732683114492
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary AzureML and authentication libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1732683117181
    }
   },
   "outputs": [],
   "source": [
    "# Define workspace configuration (replace with your details)\n",
    "workspace_config = {\n",
    "    \"subscription_id\": \"your_subscription_id\",  # Replace with your Azure subscription ID\n",
    "    \"resource_group\": \"your_resource_group\",    # Replace with your Azure resource group name\n",
    "    \"workspace_name\": \"your_workspace_name\"     # Replace with your AzureML workspace name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting workspace.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile workspace.json\n",
    "{\n",
    "    \"subscription_id\": \"####################\",\n",
    "    \"resource_group\": \"###################\",\n",
    "    \"workspace_name\": \"###############\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1732683164946
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: workspace.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7fb604621de0>,\n",
      "         subscription_id=72510a3d-1523-4e16-be26-bd516ff30c38,\n",
      "         resource_group_name=default_resource_group,\n",
      "         workspace_name=thireshworkspace)\n"
     ]
    }
   ],
   "source": [
    "# Initialize credentials for Azure authentication\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the MLClient to connect with AzureML\n",
    "ml_client = MLClient.from_config(credential=credential, path=\"workspace.json\")\n",
    "\n",
    "\n",
    "\n",
    "# Create an AzureML Workspace object\n",
    "ws = Workspace(\n",
    "    subscription_id=ml_client.subscription_id,\n",
    "    resource_group=ml_client.resource_group_name,\n",
    "    workspace_name=ml_client.workspace_name,\n",
    ")\n",
    "\n",
    "\n",
    "# Verify the client and workspace details\n",
    "print(ml_client)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Register the Reports Dataset as a Data Asset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the dataset in AzureML for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Upload  Dataset-10k.zip` file in to the Azure Machine Learning Studio before executing the below cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732683171577
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading extracted_dataset_reports (7.13 MBs): 100%|██████████| 7130176/7130176 [00:00<00:00, 57091825.93it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asset 'finsights-dataset-reports' registered successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for data registration\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the ZIP file containing Tesla annual reports\n",
    "zip_file_path = 'Dataset-10k.zip'\n",
    "\n",
    "# Directory to extract the reports\n",
    "extract_to_directory = './extracted_dataset_reports'\n",
    "os.makedirs(extract_to_directory, exist_ok=True)\n",
    "\n",
    "# Extract the ZIP file containing the reports\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_directory)\n",
    "\n",
    "# Register the extracted data as a Data asset in AzureML\n",
    "local_data_path = extract_to_directory\n",
    "data_asset = Data(\n",
    "    path=local_data_path,\n",
    "    type=AssetTypes.URI_FOLDER,  # Registering as a folder URI\n",
    "    description=\"Finsights collected reports for embedding generation\",\n",
    "    name=\"finsights-dataset-reports\"\n",
    ")\n",
    "\n",
    "# Use the MLClient to register the data asset\n",
    "ml_client.data.create_or_update(data_asset)\n",
    "print(f\"Data asset '{data_asset.name}' registered successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Set Up Azure OpenAI Connection**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Embeddings Model to use?\n",
    "\n",
    "There are currently two supported Embedding options: OpenAI's `text-embedding-ada-002` embedding model or HuggingFace embedding models. Here are some factors that might influence your decision:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI\n",
    "\n",
    "OpenAI has [great documentation](https://platform.openai.com/docs/guides/embeddings) on their Embeddings model `text-embedding-ada-002`, it can handle up to 8191 tokens and can be accessed using [Azure OpenAI](https://learn.microsoft.com/azure/cognitive-services/openai/concepts/models#embeddings-models) or OpenAI directly.\n",
    "If you have an existing Azure OpenAI Instance you can connect it to AzureML, if you don't AzureML provisions a default one for you called `Default_AzureOpenAI`.\n",
    "The main limitation when using `text-embedding-ada-002` is cost/quota available for the model. Otherwise it provides high quality embeddings across a wide array of text domains while being simple to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace\n",
    "\n",
    "HuggingFace hosts many different models capable of embedding text into single-dimensional vectors. The [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) ranks the performance of embeddings models on a few axis, not all models ranked can be run locally (e.g. `text-embedding-ada-002` is on the list), though many can and there is a range of larger and smaller models. When embedding with HuggingFace the model is loaded locally for inference, this will potentially impact your choice of compute resources.\n",
    "\n",
    "**NOTE:** The default PromptFlow Runtime does not come with HuggingFace model dependencies installed, Indexes created using HuggingFace embeddings will not work in PromptFlow by default. **Pick OpenAI if you want to use PromptFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the cells under _either_ heading (OpenAI or HuggingFace) to use the respective embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI\n",
    "\n",
    "We can use the automatically created `Default_AzureOpenAI` connection.\n",
    "\n",
    "If you would rather use an existing Azure OpenAI connection then change `aoai_connection_name` below.\n",
    "If you would rather use an existing Azure OpenAI resource, but don't have a connection created, modify `aoai_connection_name` and the details under the `# Create New Connection` code comment, or navigate the PromptFlow section in your AzureML Workspace and use the Connections create UI flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1732683178967
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# # Azure Open AI redentials and the id of the deployed chat model are stored as\n",
    "# # key value pairs in a json file\n",
    "\n",
    "# with open('config.json', 'r') as az_creds:\n",
    "#     data = az_creds.read()\n",
    "\n",
    "# # Credentials to authenticate to the personalized Open AI model server\n",
    "# import json\n",
    "# creds = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1732712479483
    }
   },
   "outputs": [],
   "source": [
    "# from azureml.rag.utils.connections import get_connection_by_name_v2, create_connection_v2\n",
    "\n",
    "# # Define the connection name for Azure OpenAI\n",
    "# aoai_connection_name = \"Custom_AzureOpenAI_Connection\"\n",
    "\n",
    "# try:\n",
    "#     # Retrieve an existing connection by name\n",
    "#     aoai_connection = get_connection_by_name_v2(ws, aoai_connection_name)\n",
    "#     aoai_connection_id = aoai_connection[\"id\"]\n",
    "# except Exception:\n",
    "#     # If the connection doesn't exist, create a new one\n",
    "#     target = creds[\"AZURE_OPENAI_ENDPOINT\"]  # Replace with your Azure OpenAI endpoint\n",
    "#     key = creds[\"AZURE_OPENAI_KEY\"]          # Replace with your Azure OpenAI API key\n",
    "#     api_version = creds[\"AZURE_OPENAI_APIVERSION\"]    # Replace with the appropriate API version\n",
    "\n",
    "#     aoai_connection = create_connection_v2(\n",
    "#         workspace=ws,\n",
    "#         name=aoai_connection_name,\n",
    "#         category=\"AzureOpenAI\",\n",
    "#         target=target,\n",
    "#         auth_type=\"ApiKey\",\n",
    "#         credentials={\"key\": key},\n",
    "#         metadata={\"ApiType\": \"azure\", \"ApiVersion\": api_version},\n",
    "#     )\n",
    "\n",
    "#     aoai_connection_id = aoai_connection[\"id\"]\n",
    "\n",
    "# print(f\"Azure OpenAI connection created or retrieved successfully: {aoai_connection_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your Workspace has a connection to Azure OpenAI we will make sure the `text-embedding-ada-002` model has been deployed ready for inference. This cell will fail if there is not deployment for the embeddings model, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a model with Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1732683180125
    }
   },
   "outputs": [],
   "source": [
    "# from azureml.rag.utils.deployment import infer_deployment\n",
    "\n",
    "# aoai_embedding_model_name = \"text-embedding-ada-002\"\n",
    "# try:\n",
    "#     aoai_embedding_deployment_name = infer_deployment(\n",
    "#         aoai_connection, aoai_embedding_model_name\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is '{aoai_embedding_deployment_name}'\"\n",
    "#     )\n",
    "# except Exception as e:\n",
    "#     print(f\"Deployment name in AOAI workspace for model '{model_name}' is not found.\")\n",
    "#     print(\n",
    "#         f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will combine the deployment and model information into a uri form which the AzureML embeddings components expect as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1732683181029
    }
   },
   "outputs": [],
   "source": [
    "# embeddings_model_uri = f\"azure_open_ai://deployment/{aoai_embedding_deployment_name}/model/{aoai_embedding_model_name}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace\n",
    "\n",
    "AzureMLs default model from HuggingFace is `all-mpnet-base-v2`, it can be run by most laptops. Any `sentence-transformer` models should be supported, you can learn more about `sentence-transformers` [here](https://huggingface.co/sentence-transformers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1732683182329
    }
   },
   "outputs": [],
   "source": [
    "embeddings_model_uri = \"hugging_face://model/sentence-transformers/all-mpnet-base-v2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Setup Pipeline to process data into Index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AzureML [Pipelines](https://learn.microsoft.com/azure/machine-learning/concept-ml-pipelines?view=azureml-api-2) connect together multiple [Components](https://learn.microsoft.com/azure/machine-learning/concept-component?view=azureml-api-2). Each Component defines inputs, code that consumes the inputs and outputs produced from the code. Pipelines themselves can have inputs, and outputs produced by connecting together individual sub Components.\n",
    "To process your data for embedding and indexing we will chain together multiple components each performing their own step of the workflow.\n",
    "\n",
    "The Components are published to a [Registry](https://learn.microsoft.com/azure/machine-learning/how-to-manage-registries?view=azureml-api-2&tabs=cli), `azureml`, which should have access to by default, it can be accessed from any Workspace.\n",
    "In the below cell we get the Component Definitions from the `azureml` registry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define Pipeline Components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1732683190698
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import the MLClient to access the AzureML registry\n",
    "ml_registry = MLClient(credential=credential, registry_name=\"azureml\")\n",
    "\n",
    "# Retrieve components for processing data, generating embeddings, and creating the FAISS index\n",
    "crack_and_chunk_component = ml_registry.components.get(\n",
    "    \"llm_rag_crack_and_chunk\", label=\"latest\"\n",
    ")\n",
    "generate_embeddings_component = ml_registry.components.get(\n",
    "    \"llm_rag_generate_embeddings\", label=\"latest\"\n",
    ")\n",
    "create_faiss_index_component = ml_registry.components.get(\n",
    "    \"llm_rag_create_faiss_index\", label=\"latest\"\n",
    ")\n",
    "register_mlindex_component = ml_registry.components.get(\n",
    "    \"llm_rag_register_mlindex_asset\", label=\"latest\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Component has documentation which provides an overall description of the Components purpose and each of the inputs/outputs.\n",
    "For example we can see understand what `crack_and_chunk` does by inspecting the Component definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1732683191429
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
      "name: llm_rag_crack_and_chunk\n",
      "version: 0.0.74\n",
      "display_name: LLM - Crack and Chunk Data\n",
      "description: 'Creates chunks no larger than `chunk_size` from `input_data`, extracted\n",
      "  document titles are prepended to each chunk\n",
      "\n",
      "\n",
      "  LLM models have token limits for the prompts passed to them, this is a limiting\n",
      "  factor at embedding time and even more limiting at prompt completion time as only\n",
      "  so much context can be passed along with instructions to the LLM and user queries.\n",
      "\n",
      "  Chunking allows splitting source data of various formats into small but coherent\n",
      "  snippets of information which can be ''packed'' into LLM prompts when asking for\n",
      "  answers to user query related to the source documents.\n",
      "\n",
      "\n",
      "  Supported formats: md, txt, html/htm, pdf, ppt(x), doc(x), xls(x), py\n",
      "\n",
      "  '\n",
      "tags:\n",
      "  Preview: ''\n",
      "type: command\n",
      "inputs:\n",
      "  input_data:\n",
      "    type: uri_folder\n",
      "    description: Uri Folder containing files to be chunked.\n",
      "    optional: false\n",
      "  input_glob:\n",
      "    type: string\n",
      "    optional: true\n",
      "    description: Limit files opened from `input_data`, defaults to '**/*'.\n",
      "  allowed_extensions:\n",
      "    type: string\n",
      "    optional: true\n",
      "    description: Comma separated list of extensions to include, if not provided the\n",
      "      default list of supported extensions will be used. e.g. '.md,.txt,.html,.py,.pdf.'\n",
      "  chunk_size:\n",
      "    type: integer\n",
      "    optional: false\n",
      "    default: '768'\n",
      "    description: Maximum number of tokens to put in each chunk.\n",
      "  chunk_overlap:\n",
      "    type: integer\n",
      "    optional: false\n",
      "    default: '0'\n",
      "    description: Number of tokens to overlap between chunks.\n",
      "  doc_intel_connection_id:\n",
      "    type: string\n",
      "    optional: true\n",
      "    description: Connection id for Document Intelligence service. If provided, will\n",
      "      be used to extract content from .pdf document.\n",
      "  data_source_url:\n",
      "    type: string\n",
      "    optional: true\n",
      "    description: Base URL to join with file paths to create full source file URL for\n",
      "      chunk metadata.\n",
      "  document_path_replacement_regex:\n",
      "    type: string\n",
      "    optional: true\n",
      "    description: 'A JSON string with two fields, ''match_pattern'' and ''replacement_pattern''\n",
      "      to be used with re.sub on the source url. e.g. ''{\"match_pattern\": \"(.*)/articles/(.*)(\\\\.[^.]+)$\",\n",
      "      \"replacement_pattern\": \"\\\\1/\\\\2\"}'' would remove ''/articles'' from the middle\n",
      "      of the url.'\n",
      "  max_sample_files:\n",
      "    type: integer\n",
      "    optional: false\n",
      "    default: '-1'\n",
      "    description: Number of files to chunk. Specify -1 to chunk all documents in input\n",
      "      path.\n",
      "  use_rcts:\n",
      "    type: string\n",
      "    optional: false\n",
      "    default: 'True'\n",
      "    description: Whether to use RecursiveCharacterTextSplitter to split documents\n",
      "      into chunks\n",
      "    enum:\n",
      "    - 'True'\n",
      "    - 'False'\n",
      "  output_format:\n",
      "    type: string\n",
      "    optional: false\n",
      "    default: jsonl\n",
      "    description: Format of the output chunk file\n",
      "    enum:\n",
      "    - csv\n",
      "    - jsonl\n",
      "outputs:\n",
      "  output_chunks:\n",
      "    type: uri_folder\n",
      "    description: Uri Folder containing chunks. Each chunk will be a separate file\n",
      "      in the folder\n",
      "command: python -m azureml.rag.tasks.crack_and_chunk --input_data '${{inputs.input_data}}'\n",
      "  $[[--input_glob '${{inputs.input_glob}}']] $[[--allowed_extensions ${{inputs.allowed_extensions}}]]\n",
      "  --output_chunks ${{outputs.output_chunks}} --chunk_size ${{inputs.chunk_size}} --chunk_overlap\n",
      "  ${{inputs.chunk_overlap}} $[[--doc_intel_connection_id ${{inputs.doc_intel_connection_id}}]]\n",
      "  $[[--data_source_url ${{inputs.data_source_url}}]] $[[--document_path_replacement_regex\n",
      "  '${{inputs.document_path_replacement_regex}}']] --max_sample_files ${{inputs.max_sample_files}}\n",
      "  --use_rcts '${{inputs.use_rcts}}' --output_format ${{inputs.output_format}}\n",
      "environment: azureml://registries/azureml/environments/llm-rag-embeddings/versions/72\n",
      "code: azureml://registries/azureml/codes/5f2b33c9-fe96-4793-ace7-7cae8d3c56c9/versions/1\n",
      "resources:\n",
      "  instance_count: 1\n",
      "creation_context:\n",
      "  created_at: '2024-11-15T00:17:58.287009+00:00'\n",
      "  created_by: Microsoft\n",
      "  created_by_type: User\n",
      "  last_modified_at: '2024-11-15T00:17:58.287009+00:00'\n",
      "  last_modified_by: Microsoft\n",
      "  last_modified_by_type: User\n",
      "id: azureml://registries/azureml/components/llm_rag_crack_and_chunk/versions/0.0.74\n",
      "is_deterministic: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(crack_and_chunk_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build the AzureML Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below a Pipeline is built by defining a python function which chains together the above components inputs and outputs. Arguments to the function are inputs to the Pipeline itself and the return value is a dictionary defining the outputs of the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1732683283890
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities._job.pipeline._io import PipelineInput\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# Utility function for automatic compute configuration\n",
    "def use_automatic_compute(component, instance_count=1, instance_type=\"Standard_NC4as_T4_v3\"):\n",
    "    \"\"\"Configure a component to use automatic compute.\"\"\"\n",
    "    component.set_resources(\n",
    "        instance_count=instance_count,\n",
    "        instance_type=instance_type,\n",
    "        properties={\"compute_specification\": {\"automatic\": True}},\n",
    "    )\n",
    "    return component\n",
    "\n",
    "\n",
    "# Utility function to check if optional pipeline inputs are provided\n",
    "def optional_pipeline_input_provided(input: Optional[PipelineInput]):\n",
    "    \"\"\"Check if optional pipeline inputs are provided.\"\"\"\n",
    "    return input is not None and input._data is not None\n",
    "\n",
    "\n",
    "@pipeline(default_compute=\"serverless\")\n",
    "def finsights_to_faiss(\n",
    "    data_asset_path: str,\n",
    "    embeddings_model: str,\n",
    "    asset_name: str,\n",
    "    chunk_size: int = 1024,\n",
    "    data_source_glob: str = None,\n",
    "    document_path_replacement_regex: str = None,\n",
    "    aoai_connection_id=None,\n",
    "    embeddings_container=None,\n",
    "):\n",
    "    \"\"\"Pipeline to process finsights reports and create a FAISS vector index.\"\"\"\n",
    "    \n",
    "    # Step 1: Chunk data into smaller pieces\n",
    "    crack_and_chunk = crack_and_chunk_component(\n",
    "        input_data=Input(type=\"uri_folder\", path=data_asset_path),  # Input data asset\n",
    "        input_glob=data_source_glob,\n",
    "        chunk_size=chunk_size,\n",
    "        document_path_replacement_regex=document_path_replacement_regex,\n",
    "    )\n",
    "    use_automatic_compute(crack_and_chunk)  # Apply compute configuration\n",
    "\n",
    "    # Step 2: Generate embeddings for the data chunks\n",
    "    generate_embeddings = generate_embeddings_component(\n",
    "        chunks_source=crack_and_chunk.outputs.output_chunks,\n",
    "        embeddings_container=embeddings_container,\n",
    "        embeddings_model=embeddings_model,\n",
    "    )\n",
    "    use_automatic_compute(generate_embeddings)  # Apply compute configuration\n",
    "    \n",
    "    # Optional: Include Azure OpenAI connection ID\n",
    "    if optional_pipeline_input_provided(aoai_connection_id):\n",
    "        generate_embeddings.environment_variables[\n",
    "            \"AZUREML_WORKSPACE_CONNECTION_ID_AOAI\"\n",
    "        ] = aoai_connection_id\n",
    "    \n",
    "    if optional_pipeline_input_provided(embeddings_container):\n",
    "        generate_embeddings.outputs.embeddings = Output(\n",
    "            type=\"uri_folder\", path=f\"{embeddings_container.path}/{{name}}\"\n",
    "        )\n",
    "\n",
    "    # Step 3: Create a FAISS vector index from embeddings\n",
    "    create_faiss_index = create_faiss_index_component(\n",
    "        embeddings=generate_embeddings.outputs.embeddings,\n",
    "    )\n",
    "    use_automatic_compute(create_faiss_index)  # Apply compute configuration\n",
    "\n",
    "    # Step 4: Register the FAISS index as an MLIndex asset\n",
    "    register_mlindex = register_mlindex_component(\n",
    "        storage_uri=create_faiss_index.outputs.index, \n",
    "        asset_name=asset_name\n",
    "    )\n",
    "    use_automatic_compute(register_mlindex) # Apply compute configuration\n",
    "    \n",
    "    return {\n",
    "        \"mlindex_asset_uri\": create_faiss_index.outputs.index,\n",
    "        \"mlindex_asset_id\": register_mlindex.outputs.asset_id,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.Submit the Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers how to instantiate the AzureML pipeline, configure its inputs, and submit it for execution. The pipeline processes the data, generates embeddings, creates a FAISS-based vector index, and registers the output as an AzureML asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1732683293914
    }
   },
   "outputs": [],
   "source": [
    "# Define the asset name and data source glob pattern\n",
    "asset_name = \"finsights_faiss_index\"  # Name for the FAISS index asset\n",
    "data_source_glob = \"**/*.pdf\"  # Pattern to match input data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1732683294882
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore path: azureml://subscriptions/72510a3d-1523-4e16-be26-bd516ff30c38/resourcegroups/default_resource_group/workspaces/thireshworkspace/datastores/workspaceblobstore/paths/LocalUpload/d1b3eb074c8f06ba2272ac8a49b6ec0a/extracted_dataset_reports/\n"
     ]
    }
   ],
   "source": [
    "# Get the input data asset path from the workspace datastore\n",
    "datastore_path = ml_client.data.get(\"finsights-dataset-reports\", version=\"1\").path\n",
    "print(f\"Datastore path: {datastore_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gather": {
     "logged": 1732683312821
    }
   },
   "outputs": [],
   "source": [
    "# Create the pipeline job by calling the defined pipeline function\n",
    "pipeline_job = finsights_to_faiss(\n",
    "    embeddings_model=embeddings_model_uri,  # URI of the embeddings model\n",
    "    #aoai_connection_id=aoai_connection_id,  # Connection ID for Azure OpenAI (optional)\n",
    "    embeddings_container=Input(\n",
    "        type=\"uri_folder\",\n",
    "        path=f\"azureml://datastores/workspaceblobstore/paths/embeddings/{asset_name}\"\n",
    "    ),  # Path for storing generated embeddings\n",
    "    data_asset_path=Input(\n",
    "        type=\"uri_folder\",\n",
    "        path=datastore_path\n",
    "    ),  # Input data asset path\n",
    "    chunk_size=1024,  # Size of chunks for processing\n",
    "    data_source_glob=data_source_glob,  # Glob pattern for input files\n",
    "    asset_name=asset_name  # Name of the MLIndex asset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1732683314486
    }
   },
   "outputs": [],
   "source": [
    "# Add properties for better indexing and artifact tracking in the AzureML UI\n",
    "pipeline_job.properties[\"azureml.mlIndexAssetName\"] = asset_name\n",
    "pipeline_job.properties[\"azureml.mlIndexAssetKind\"] = \"faiss\"\n",
    "pipeline_job.properties[\"azureml.mlIndexAssetSource\"] = \"Data asset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1732683318451
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFileJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline submitted successfully! Job ID: /subscriptions/72510a3d-1523-4e16-be26-bd516ff30c38/resourceGroups/default_resource_group/providers/Microsoft.MachineLearningServices/workspaces/thireshworkspace/jobs/upbeat_plow_phfttszdps\n"
     ]
    }
   ],
   "source": [
    "# Submit the pipeline job for execution\n",
    "submitted_pipeline = ml_client.jobs.create_or_update(pipeline_job)\n",
    "print(f\"Pipeline submitted successfully! Job ID: {submitted_pipeline.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1732684293103
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: upbeat_plow_phfttszdps\n",
      "Web View: https://ml.azure.com/runs/upbeat_plow_phfttszdps?wsid=/subscriptions/72510a3d-1523-4e16-be26-bd516ff30c38/resourcegroups/default_resource_group/workspaces/thireshworkspace\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2024-11-27 04:55:21Z] Submitting 1 runs, first five are: f961e282:deda3541-d530-46e7-b33a-f0deb0b93a8d\n",
      "[2024-11-27 05:04:02Z] Completing processing run id deda3541-d530-46e7-b33a-f0deb0b93a8d.\n",
      "[2024-11-27 05:04:03Z] Submitting 1 runs, first five are: d9e298ba:e882655c-fa7f-4780-aad5-1fbde32d3f25\n",
      "[2024-11-27 05:08:52Z] Completing processing run id e882655c-fa7f-4780-aad5-1fbde32d3f25.\n",
      "[2024-11-27 05:08:53Z] Submitting 1 runs, first five are: 8dcba5ad:08a9aad7-5853-4866-948b-d6ff66ee6a08\n",
      "[2024-11-27 05:09:56Z] Completing processing run id 08a9aad7-5853-4866-948b-d6ff66ee6a08.\n",
      "[2024-11-27 05:09:56Z] Submitting 1 runs, first five are: 8a6918dd:5600724a-0f60-41f5-9b3f-ed238a9df903\n",
      "[2024-11-27 05:10:53Z] Completing processing run id 5600724a-0f60-41f5-9b3f-ed238a9df903.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: upbeat_plow_phfttszdps\n",
      "Web View: https://ml.azure.com/runs/upbeat_plow_phfttszdps?wsid=/subscriptions/72510a3d-1523-4e16-be26-bd516ff30c38/resourcegroups/default_resource_group/workspaces/thireshworkspace\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stream the pipeline job logs for real-time monitoring\n",
    "ml_client.jobs.stream(submitted_pipeline.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# **Information Retrieval and Response Generation Using LangChain-FAISS and Azure OpenAI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section focuses on retrieving information from pre-indexed data using FAISS (Facebook AI Similarity Search) and generating responses with Azure OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.Installing Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gather": {
     "logged": 1732684551973
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (0.3.8)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (3.10.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (0.1.146)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (1.23.5)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
      "Requirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Install the required LangChain and HuggingFace libraries\n",
    "%pip install -U langchain-community\n",
    "%pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Setting Up Data Retrieval**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Downloading and Setting Up FAISS Index Assets**\n",
    "\n",
    "This step ensures that we download the necessary FAISS index and associated metadata from Azure ML. FAISS is a powerful tool for similarity search, and here, the pre-trained index will serve as the backbone for retrieving relevant documents based on user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1732684575343
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./finsightsfaissindexasset/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary utilities for artifact retrieval\n",
    "import azure.ai.ml._artifacts._artifact_utilities as artifact_utils\n",
    "\n",
    "# Retrieve the path to the latest FAISS index asset from Azure ML\n",
    "data_info = ml_client.data.get(name=asset_name, label=\"latest\").path\n",
    "\n",
    "# Download the FAISS index asset to a local directory\n",
    "artifact_utils.download_artifact_from_aml_uri(\n",
    "    uri=data_info,\n",
    "    destination=\"./finsightsfaissindexasset/\",\n",
    "    datastore_operation=ml_client.datastores\n",
    ")\n",
    "\n",
    "# The FAISS index asset will be used for vector-based similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Loading the FAISS Index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the FAISS Index and Preparing the Retriever**\n",
    "\n",
    "We load the FAISS index from the downloaded files and connect it to an embedding model. This embedding model ensures that queries are converted into vector space to match the stored documents effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gather": {
     "logged": 1732684585300
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Path to the directory containing FAISS index files\n",
    "index_folder_path = \"./finsightsfaissindexasset/\"\n",
    "\n",
    "# Specify the embedding model used during FAISS index creation\n",
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# Load the FAISS index and associate it with the embedding model\n",
    "retriever = FAISS.load_local(\n",
    "    folder_path=index_folder_path, \n",
    "    embeddings=embedding_model, \n",
    "    allow_dangerous_deserialization=True  # Acknowledge the source of the data for safe loading\n",
    ")\n",
    "\n",
    "# The retriever is now ready to perform similarity searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Performing a Similarity Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1732684588168
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: Title: google-10-k-2023.pdf•Collaboration Tools:  Google Workspace and Duet AI in Google Workspace provide easy-to-use, secure \n",
      "communication and collaboration tools, including apps like Gmail, Docs, Drive, Calendar, Meet, and more. \n",
      "These tools enable secure hybrid and remote work, boosting productivity and collaboration. AI has been used \n",
      "in Google Workspace for years to improve grammar, efficiency, security, and more with features like Smart \n",
      "Reply, Smart Compose, and malware and phishing protection in Gmail.  Duet AI in Google Workspace helps \n",
      "users write, organize, visualize, accelerate workflows, and have richer meetings.\n",
      "•AI Platform and Duet AI for Google Cloud:  Our Vertex AI platform gives developers the ability to train, tune, \n",
      "augment, and deploy applications using generative AI models and services such as Enterprise Search and \n",
      "Conversations. Duet AI for Google Cloud provides pre-packaged AI agents that assist developers to write, test, \n",
      "document, and operate software.\n",
      "Other Bets\n",
      " Across Alphabet, we are also using technology to try to solve big problems that affect a wide variety of industries \n",
      "from improving transportation and health technology to exploring solutions to address climate change. Alphabet’s \n",
      "investment in the portfolio of Other Bets includes businesses that are at various stages of development, ranging from \n",
      "those in the R&D phase to those that are in the beginning stages of commercialization. Our goal is for them to become \n",
      "thriving, successful businesses. Other Bets operate as independent companies and some of them have their own \n",
      "boards with independent members and outside investors. While these early-stage businesses naturally come with \n",
      "considerable uncertainty, s ome of them are already generating revenue and making important strides in their \n",
      "industries.  Revenues from Other Bets are generated primarily from the sale of healthcare-related services and internet \n",
      "services.\n",
      "Competition\n",
      "Our business is characterized by rapid change as well as new and disruptive technologies. We face formidable \n",
      "competition in every aspect of our business, including, among others, from:\n",
      "•general purpose search engines and information services;\n",
      "•vertical search engines and e-commerce providers for queries related to travel, jobs, and health, which users \n",
      "may navigate directly to rather than go through Google;\n",
      "•online advertising platforms and networks;\n",
      "•other forms of advertising, such as billboards, magazines, newspapers, radio, and television as our advertisers \n",
      "typically advertise in multiple media, both online and offline;\n",
      "•digital content and application platform providers;\n",
      "•providers of enterprise cloud services;\n",
      "•developers  and providers of AI products and services ;\n",
      "•companies that design, manufacture, and market consumer hardware products, including businesses that \n",
      "have developed proprietary platforms;\n",
      "•providers of digital video services; \n",
      "•social networks, which users may rely on for product or service referrals, rather than seeking information \n",
      "through traditional search engines;\n",
      "•providers of workspace communication and connectivity products; and \n",
      "•digital assistant providers .\n",
      "Competing successfully depends heavily on our ability to develop and distribute innovative products and \n",
      "technologies to the marketplace across our businesses. For example, for advertising, competing successfully depends \n",
      "on attracting and retaining:\n",
      "•users, for whom other products and services are literally one click away, largely on the basis of the relevance \n",
      "of our advertising, as well as the general usefulness, security, and availability of our products and services;\n",
      "•advertisers, primarily based on our ability to generate sales leads, and ultimately customers, and to deliver \n",
      "their advertisements in an efficient and effective manner across a variety of distribution channels; and\n",
      "•content providers, primarily based on the quality of our advertiser base, our ability to help these partners \n",
      "generate revenues from advertising, and the terms of our agreements with them.Table of Contents Alphabet Inc.\n",
      "8.  \n",
      "Metadata: {'source_doc_id': 'google-10-k-2023.pdf10', 'chunk_hash': '351b119ca50267cc8bd555458aff6bb9a831fb5ff8618ee3e73716c143b42b5d', 'mtime': None, 'page_number': 8, 'stats': {'tiktokens': 764, 'chars': 4082, 'lines': 49}, 'source': {'filename': 'google-10-k-2023.pdf', 'url': 'google-10-k-2023.pdf', 'mtime': 1732683169.0}}\n",
      "Document: Title: msft-10-k-2023.pdf11 • Build the intelligent cloud and intelligent edge platform.  \n",
      "• Create more personal computing.  \n",
      "Reinvent Productivity and Business Processes  \n",
      "At Microsoft, we provide technology and resources to help our customers create a secure, productive work environment. \n",
      "Our family of products plays a key role in the ways the world works, learns, and connects.  \n",
      "Our growth depends on securely delivering continuous innovation and advancing our leading productivity and collaboration \n",
      "tools and services, including Office 365, Dynamics 365, and LinkedIn. Microsoft 365 brings together Office 365, Windows, \n",
      "and Enterprise  Mobility + Security to help organizations empower their employees with AI -backed tools that unlock creativity, \n",
      "increase collaboration, and fuel innovation, all the while enabling compliance coverage and data protection. Microsoft Teams \n",
      "is a comprehensive platform for work, with meetings, calls, chat, collaboration, and business process automation. Microsoft \n",
      "Viva is an employee experience platform that brings together communications, knowledge, learning, resources, and \n",
      "insights. Microsoft 365 Copilot combin es next -generation AI with business data in the Microsoft Graph and Microsoft 365 \n",
      "applications.  \n",
      "Together with the Microsoft Cloud, Dynamics 365, Microsoft Teams, and our AI offerings bring a new era of collaborative \n",
      "applications that optimize business fun ctions, processes, and applications to better serve customers and employees while \n",
      "creating more business value. Microsoft Power Platform is helping domain experts drive productivity gains with low -code/no -\n",
      "code tools, robotic process automation, virtual age nts, and business intelligence. In a dynamic labor market, LinkedIn is \n",
      "helping professionals use the platform to connect, learn, grow, and get hired.  \n",
      "Build the Intelligent Cloud and Intelligent Edge Platform  \n",
      "As digital transformation and adoption of AI a ccelerates and revolutionizes more business workstreams, organizations in \n",
      "every sector across the globe can address challenges that will have a fundamental impact on their success. For enterprises, \n",
      "digital technology empowers employees, optimizes operation s, engages customers, and in some cases, changes the very \n",
      "core of products and services. We continue to invest in high performance and sustainable computing to meet the growing \n",
      "demand for fast access to Microsoft services provided by our network of cloud c omputing infrastructure and datacenters.  \n",
      "Our cloud business benefits from three economies of scale: datacenters that deploy computational resources at significantly \n",
      "lower cost per unit than smaller ones; datacenters that coordinate and aggregate diverse c ustomer, geographic, and \n",
      "application demand patterns, improving the utilization of computing, storage, and network resources; and multi -tenancy \n",
      "locations that lower application maintenance labor costs.  \n",
      "The Microsoft Cloud provides the best integration acr oss the technology stack while offering openness, improving time to \n",
      "value, reducing costs, and increasing agility. Being a global -scale cloud, Azure uniquely offers hybrid consistency, developer \n",
      "productivity, AI capabilities, and trusted security and compl iance. We see more emerging use cases and needs for compute \n",
      "and security at the edge and are accelerating our innovation across the spectrum of intelligent edge devices, from Internet \n",
      "of Things (“IoT”) sensors to gateway devices and edge hardware to build,  manage, and secure edge workloads.  \n",
      "Our AI platform, Azure AI, is helping organizations transform, bringing intelligence and insights to the hands of their \n",
      "employees and customers to solve their most pressing challenges. Organizations large and small are deploying Azure AI \n",
      "solutions to achieve more at scale, more easily, with the proper enterprise -level and responsible AI protections.  \n",
      "  \n",
      "We have a long -term partnership with OpenAI, a leading AI research and deployment company. We deploy OpenAI’s \n",
      "models acr oss our consumer and enterprise products. As OpenAI’s exclusive cloud provider, Azure powers all of OpenAI’s \n",
      "workloads. We have also increased our investments in the development and deployment of specialized supercomputing \n",
      "systems to accelerate OpenAI’s re search.  \n",
      "Our hybrid infrastructure offers integrated, end -to-end security, compliance, identity, and management capabilities to \n",
      "support the real -world needs and evolving regulatory requirements of commercial customers and enterprises. Our industry \n",
      "clouds b ring together capabilities across the entire Microsoft Cloud, along with industry -specific customizations. Azure Arc \n",
      "simplifies governance and management by delivering a consistent multi -cloud and on -premises management platform.  \n",
      "Nuance, a leader in conve rsational AI and ambient intelligence across industries including healthcare, financial services, \n",
      "retail, and telecommunications, joined Microsoft in 2022. Microsoft and Nuance enable organizations to accelerate their \n",
      "business goals with security -focused, cloud -based solutions infused with AI.  \n",
      "Metadata: {'source_doc_id': 'msft-10-k-2023.pdf12', 'chunk_hash': '6fd4ce6538860ee8e9d272065316a99a8c723d85a7e7404c1eb0f9dac5fff459', 'mtime': None, 'page_number': 11, 'stats': {'tiktokens': 952, 'chars': 5106, 'lines': 48}, 'source': {'filename': 'msft-10-k-2023.pdf', 'url': 'msft-10-k-2023.pdf', 'mtime': 1732683169.0}}\n",
      "Document: Title: msft-10-k-2023.pdf3 All up, Dynamics surpassed $5  billion in revenue over the past fiscal year, with our customer experience, service, and \n",
      "finance and supply chain businesses each surp assing $1  billion in annual sales.  \n",
      "Industry  \n",
      "Across industries, we are rapidly becoming the partner of choice for any organization looking to generate real value from \n",
      "AI. In healthcare, for example, we introduced the world’s first fully automated clinical  documentation application, DAX \n",
      "Copilot. The application helps physicians reduce documentation time by half, freeing them to spend more time face to face \n",
      "with patients. And Epic will integrate it directly into its electronic health records system.  \n",
      "And, in  retail, we introduced new tools to help companies manage their day -to-day operations and digitize their physical \n",
      "stores.  \n",
      "Modern work  \n",
      "We are rapidly evolving Microsoft 365 into an AI -first platform that enables every individual to amplify their creativit y and \n",
      "productivity, with both our established applications like Office and Teams, as well as new apps like Designer, Stream, and \n",
      "Loop. Microsoft 365 is designed for today’s digitally connected, distributed workforce.  \n",
      "This year, we also introduced a new pi llar of customer value with Microsoft 365 Copilot, which combines next -generation AI \n",
      "with business data in the Microsoft Graph and Microsoft 365 applications to help people be more productive and unleash \n",
      "their creativity at work. Just last month, I was exc ited to announce that we will make Microsoft 365 Copilot generally available \n",
      "to our commercial customers later this year.  \n",
      "We continue to build momentum in Microsoft Teams across collaboration, chat, meetings, and calls. We introduced a new \n",
      "version of Team s that delivers up to two times faster performance, while using 50  percent less memory. We also introduced \n",
      "Teams Premium to meet enterprise demand for AI -powered features like intelligent meeting recaps. All up, Teams usage \n",
      "surpassed 300  million monthly ac tive users this year.  \n",
      "With Microsoft Viva, we have created a new category for employee experience. Copilot in Viva offers leaders a new way to \n",
      "build high -performance teams by prioritizing both productivity and employee engagement. This year, Viva surpasse d \n",
      "35 million monthly active users.  \n",
      "  \n",
      "Security  \n",
      "As the rate and pace of cyberthreats continue to accelerate, security is a top priority for every organization. Our \n",
      "comprehensive, AI -powered solutions give defenders the advantage. With Security Copilot, we’ re combining large language \n",
      "models with a domain -specific model informed by our threat intelligence and 65 trillion daily security signals, to transform \n",
      "every aspect of security operations center productivity.  \n",
      "All up, more than 1  million organizations now  count on our comprehensive, AI -powered solutions to protect their digital \n",
      "estates, and our security business surpassed $20  billion in annual revenue, as we help protect customers across clouds \n",
      "and endpoint platforms.  \n",
      "Search, advertising, and news  \n",
      "We are  reshaping daily search and web habits with our new Bing and Microsoft Edge browser, which brings together search, \n",
      "browsing, chat, and AI into one unified experience to deliver better search, more complete answers, a new chat experience, \n",
      "and the ability to  generate content. We think of these tools as an AI copilot for the web.  \n",
      "We are also bringing these breakthrough capabilities to businesses, with Bing Chat Enterprise, which offers commercial \n",
      "data protection, providing an easy on -ramp for any organization  looking to get the benefit of next -generation AI today.  \n",
      "Although it’s early in our journey, Bing users engaged in more than 1  billion chats and created more than 750  million images \n",
      "over the past year as they apply these new tools to get things done. And Edge has taken share for nine consecutive quarters.  \n",
      "Metadata: {'source_doc_id': 'msft-10-k-2023.pdf3', 'chunk_hash': '9355f9aca0753366aa911c44b6b8cddd7c87a6273bf3a534c2078c418eb6ba44', 'mtime': None, 'page_number': 3, 'stats': {'tiktokens': 794, 'chars': 3900, 'lines': 41}, 'source': {'filename': 'msft-10-k-2023.pdf', 'url': 'msft-10-k-2023.pdf', 'mtime': 1732683169.0}}\n"
     ]
    }
   ],
   "source": [
    "# Define a query to test the retriever\n",
    "query = \"How is the company integrating AI across their various business units\"\n",
    "\n",
    "# Retrieve the top 3 most relevant documents\n",
    "results = retriever.similarity_search(query, k=3)\n",
    "\n",
    "# Display the results\n",
    "for doc in results:\n",
    "    print(f\"Document: {doc.page_content}\\nMetadata: {doc.metadata}\")\n",
    "\n",
    "# This step helps validate that the retriever is functioning as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## **5: Creating the System and User Prompt Templates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts guide the Azure OpenAI model to generate accurate responses. Here, we define two parts:\n",
    "\n",
    "    1. The system message describing the assistant's role.\n",
    "    2. A user message template including context and the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1732684607309
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Define the system prompt for the Azure OpenAI model\n",
    "qna_system_message = \"\"\"\n",
    "You are an assistant to a Financial Analyst. Your task is to summarize and provide relevant information to the financial analyst's question based on the provided context.\n",
    "\n",
    "User input will include the necessary context for you to answer their questions. This context will begin with the token: ###Context.\n",
    "The context contains references to specific portions of documents relevant to the user's query, along with page number from the report.\n",
    "The source for the context will begin with the token ###Page\n",
    "\n",
    "When crafting your response:\n",
    "1. Select only context relevant to answer the question.\n",
    "2. Include the source links in your response.\n",
    "3. User questions will begin with the token: ###Question.\n",
    "4. If the question is irrelevant or if the context is empty - \"Sorry, this is out of my knowledge base\"\n",
    "\n",
    "Please adhere to the following guidelines:\n",
    "- Your response should only be about the question asked and nothing else.\n",
    "- Answer only using the context provided.\n",
    "- Do not mention anything about the context in your final answer.\n",
    "- If the answer is not found in the context, it is very very important for you to respond with \"Sorry, this is out of my knowledge base\"\n",
    "- If NO CONTEXT is provided, it is very important for you to respond with \"Sorry, this is out of my knowledge base\"\n",
    "\n",
    "Here is an example of how to structure your response:\n",
    "\n",
    "Answer:\n",
    "[Answer]\n",
    "\n",
    "Page:\n",
    "[Page number]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Define the user message template\n",
    "qna_user_message_template = \"\"\"\n",
    "###Context\n",
    "Here are some documents and their page number that are relevant to the question mentioned below.\n",
    "{context}\n",
    "\n",
    "###Question\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### **6. Generating the Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1732684625068
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Install the rquired packages\n",
    "!pip install openai==1.2.0 tiktoken==0.6 session-info --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gather": {
     "logged": 1732684625263
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gather": {
     "logged": 1732684625456
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load Azure OpenAI credentials\n",
    "with open('config.json', 'r') as az_creds:\n",
    "    data = az_creds.read()\n",
    "\n",
    "creds = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "gather": {
     "logged": 1732684625636
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=creds[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=creds[\"AZURE_OPENAI_KEY\"],\n",
    "    api_version=creds[\"AZURE_OPENAI_APIVERSION\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "gather": {
     "logged": 1732684626371
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Define a sample user input question\n",
    "user_input = \"How much is the company investing in research and development, and what are the key areas of focus for innovation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "gather": {
     "logged": 1732684627948
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve relevant document chunks\n",
    "relevant_document_chunks = retriever.similarity_search(user_input, k=3)\n",
    "context_list = [d.page_content for d in relevant_document_chunks]\n",
    "\n",
    "# Combine document chunks into a single context\n",
    "context_for_query = \". \".join(context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "gather": {
     "logged": 1732684630804
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company is investing $27,195 million in research and development for the fiscal year 2023, which is an increase of $2.7 billion or 11% compared to the previous year. The key areas of focus for innovation include cloud engineering, AI, digital work and life experiences, devices, and operating systems.\n",
      "\n",
      "Page:\n",
      "23, 33\n"
     ]
    }
   ],
   "source": [
    "# Compose the prompt\n",
    "prompt = [\n",
    "    {'role': 'system', 'content': qna_system_message},\n",
    "    {'role': 'user', 'content': qna_user_message_template.format(\n",
    "         context=context_for_query,\n",
    "         question=user_input\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate the response using Azure OpenAI\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=creds[\"CHATGPT_MODEL\"],\n",
    "        messages=prompt,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Extract and print the model's response\n",
    "    response = response.choices[0].message.content.strip()\n",
    "except Exception as e:\n",
    "    response = f'Sorry, I encountered the following error: \\n {e}'\n",
    "\n",
    "\n",
    "print(response)\n",
    "\n",
    "# The model uses the context to answer the user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
